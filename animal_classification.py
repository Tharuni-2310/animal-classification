# -*- coding: utf-8 -*-
"""Animal Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VG_bNJVZG-l-guaY060NwMSgiaEKRa6k
"""

import os
import numpy as np
from bing_image_downloader import downloader
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing import image
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

animals = ['Dog', 'Cat', 'Cow', 'Monkey', 'Elephant']
for animal in animals:
    downloader.download(animal, limit=30, output_dir='images', adult_filter_off=True)

model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')

def extract_features(img_path):
    img = image.load_img(img_path, target_size=(150,150))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    features = model.predict(x)
    return features.flatten()

DATADIR = './images'
features = []
labels = []
label_names = []

for i, animal in enumerate(animals):
    folder = os.path.join(DATADIR, animal)
    if not os.path.exists(folder):
        print(f"Folder for {animal} not found, skipping...")
        continue
    for img_file in os.listdir(folder):
        img_path = os.path.join(folder, img_file)
        try:
            feat = extract_features(img_path)
            features.append(feat)
            labels.append(i)
        except Exception as e:
            print(f"Error processing {img_file}: {e}")

features = np.array(features)
labels = np.array(labels)

X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)

param_grid = [
    {'C': [1, 10, 100], 'kernel': ['linear']},
    {'C': [1, 10, 100], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}
]
svc = SVC(probability=True)
clf = GridSearchCV(svc, param_grid, cv=3)
clf.fit(X_train, y_train)

print("Best parameters found:", clf.best_params_)

y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {acc:.2f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=animals))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=animals, yticklabels=animals)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

import requests
from PIL import Image
from io import BytesIO
from tensorflow.keras.preprocessing import image
import numpy as np

def predict_from_url(img_url):
    try:
        response = requests.get(img_url)
        img_data = BytesIO(response.content)
        img = Image.open(img_data).convert('RGB')
        img = img.resize((150, 150))

        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)

        features = model.predict(x).flatten().reshape(1, -1)
        pred = clf.predict(features)[0]

        print(f"Predicted class for URL {animals[pred]}")
    except Exception as e:
        print(f"Failed to process URL '{img_url}': {e}")

print("Enter image URLs one by one. Type 'done' when finished.")

while True:
    url = input("Enter image URL: ")
    if url.lower() == 'done':
        break
    predict_from_url(url)

